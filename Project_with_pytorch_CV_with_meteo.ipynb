{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfCzu0V6rU2W"
      },
      "source": [
        "# LAPD lab - Machine learning project\n",
        "\n",
        "This project aims to predict the GHI two hours in advance locally, from meteo data, date data and webcam images.\n",
        "\n",
        "We are providing a machine learning model to achieve this task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sewTy6E9tfYy"
      },
      "source": [
        "## Environnement and data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG2LbXBUsOfd"
      },
      "source": [
        "First, we import all important packages, data, and set the seed (for torch)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VAAcv9Gu8edl"
      },
      "outputs": [],
      "source": [
        "#importing packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import Ridge, ElasticNet, LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "import h5py\n",
        "import sys\n",
        "import datetime\n",
        "import math\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
        "from torch.utils.data.sampler import SequentialSampler\n",
        "from torchvision import transforms, utils\n",
        "import cv2\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "from google.colab import files ### file.download() to download a file from colab instead of right clicking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKwI1c8PHrry",
        "outputId": "dff366d2-1b9a-4c9f-8da0-c33b1e59ad37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f62425289f0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Set fixed random number seed\n",
        "torch.manual_seed(3174)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mounting the drive\n",
        "You may need to adjust the path according to your needs."
      ],
      "metadata": {
        "id": "Heb5dkJLuUi9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYpUjFMl90-U",
        "outputId": "ea64dddb-b579-445f-a17e-fafd63f98807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "time.npy\n",
            "new_irradiance.xlsx\n",
            "labels.npy\n",
            "ground_truth.npy\n",
            "persistent_level.npy\n",
            "meteo.xlsx\n",
            "X.npy\n"
          ]
        }
      ],
      "source": [
        "#Mounting Drive\n",
        "from google.colab import drive\n",
        "# # # # This will prompt for authorization.\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "## change path to where the folder of the images is\n",
        "#path = 'drive/MyDrive/Colab Notebooks/CSS 433/data' #antonin\n",
        "#path = 'drive/MyDrive/master/CSS 433/data' #Jade\n",
        "#path = 'drive/MyDrive/data' #Jade ordi 2\n",
        "path = 'drive/MyDrive/CSS 433/data' #Alison\n",
        "\n",
        "for file in os.listdir(path):\n",
        "  print(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my5bHkMYsqRT"
      },
      "source": [
        "### Below we create a class GHIDataset.\n",
        "\n",
        "This class allows us to load the dataset and access each element individually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8Pu3cPwN_8QG"
      },
      "outputs": [],
      "source": [
        "class GHIDataset(Dataset):\n",
        "    \"\"\"GHI dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, labels, images, meteo, GHI, time, transform_images=None, transform_label=None, normalise_meteo=False):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            root_dir  (string) : Path to folder with all the files.\n",
        "            labels    (string) : Name of the file with labels.\n",
        "            images    (string) : Name of the file with images.\n",
        "            meteo     (string) : Name of the file with the meteo data\n",
        "            GHI       (string) : Name of the file with the GHI (ground truth)\n",
        "            time      (string) : Name of the file with the time at which the data (meteo and images) has been acquired\n",
        "            transform_images (callable, optional): Optional transform to be applied to the images.\n",
        "            transform_label  (callable, optional): Optional transform to be applied to the label.\n",
        "            transform_meteo  (bool, optional)    : Optional normalisation to be applied to the meteo data.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        self.root_dir = root_dir\n",
        "        self.labels = torch.from_numpy(np.load(os.path.join(self.root_dir,labels)))\n",
        "        self.images = np.load(os.path.join(self.root_dir,images),mmap_mode='c')\n",
        "\n",
        "        # Define the transforms to apply to labels or input\n",
        "        self.transform_images = transform_images\n",
        "        self.transform_label = transform_label\n",
        "        self.normalise_meteo = normalise_meteo\n",
        "\n",
        "        self.GHI = np.load(os.path.join(path, GHI),allow_pickle=True)\n",
        "\n",
        "        df = pd.read_excel(os.path.join(self.root_dir, meteo))\n",
        "\n",
        "        time_image = np.load(os.path.join(self.root_dir, time),allow_pickle=True)\n",
        "\n",
        "        # Extract day, month, and year using list comprehension\n",
        "        date = [(dt.day, dt.month, dt.year, dt.hour, dt.minute) if isinstance(dt, datetime) else\n",
        "         (datetime.strptime(dt, '%Y-%m-%d %H:%M:%S').day,\n",
        "          datetime.strptime(dt, '%Y-%m-%d %H:%M:%S').month,\n",
        "          datetime.strptime(dt, '%Y-%m-%d %H:%M:%S').year,\n",
        "          datetime.strptime(dt, '%Y-%m-%d %H:%M:%S').hour,\n",
        "          datetime.strptime(dt, '%Y-%m-%d %H:%M:%S').minute)\n",
        "         for dt in time_image]\n",
        "\n",
        "        # Transpose the list of tuples using zip\n",
        "        day_, month_, year_, hour_, minute_ = zip(*date)\n",
        "\n",
        "        # Convert the individual columns to PyTorch tensors and normalise if required\n",
        "        if normalise_meteo:\n",
        "          self.day = torch.tensor(preprocessing.normalize([day_])[0])\n",
        "          self.month = torch.tensor(preprocessing.normalize([month_])[0])\n",
        "          self.year = torch.tensor(preprocessing.normalize([year_])[0])\n",
        "          self.hour = torch.tensor(preprocessing.normalize([hour_])[0])\n",
        "          self.minute = torch.tensor(preprocessing.normalize([minute_])[0])\n",
        "          self.air_temp = torch.from_numpy(preprocessing.normalize([df['Air_temp'].values])[0])\n",
        "          self.wind_speed = torch.from_numpy(preprocessing.normalize([df['Wind_speed'].values])[0])\n",
        "          self.wind_dir = torch.from_numpy(preprocessing.normalize([df['Wind_dir'].values])[0])\n",
        "        else:\n",
        "          self.day = torch.tensor(day_)\n",
        "          self.month = torch.tensor(month_)\n",
        "          self.year = torch.tensor(year_)\n",
        "          self.hour = torch.tensor(hour_)\n",
        "          self.minute = torch.tensor(minute_)\n",
        "          self.air_temp = torch.from_numpy(df['Air_temp'].values)\n",
        "          self.wind_speed = torch.from_numpy(df['Wind_speed'].values)\n",
        "          self.wind_dir = torch.from_numpy(df['Wind_dir'].values)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.labels.size()[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            idx (list or torch.Tensor) : list of two dimension indicating which sample\n",
        "                                         to get and which webcam.\n",
        "        \"\"\"\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        # Import from memory only the data (images, meteo, GHI and time) that we want\n",
        "        image0 = np.array(self.images[idx,0])\n",
        "        image1 = np.array(self.images[idx,1])\n",
        "        labels = self.labels[idx]\n",
        "\n",
        "        GHI = self.GHI[idx]\n",
        "        day = self.day[idx]\n",
        "        month = self.month[idx]\n",
        "        year = self.year[idx]\n",
        "        hour = self.hour[idx]\n",
        "        minute = self.minute[idx]\n",
        "        air_temp = self.air_temp[idx]\n",
        "        wind_speed = self.wind_speed[idx]\n",
        "        wind_dir = self.wind_dir[idx]\n",
        "\n",
        "\n",
        "        # Apply the transforms\n",
        "        if self.transform_images:\n",
        "            image0 = self.transform_images(image0)\n",
        "            image1 = self.transform_images(image1)\n",
        "\n",
        "        if self.transform_label:\n",
        "            labels = self.transform_label(labels)\n",
        "\n",
        "        return image0,image1,day, month, year, hour, minute, GHI, air_temp, wind_speed, wind_dir, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzLKJARxtQmb"
      },
      "source": [
        "Below we load the dataset and transfom the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "abs-UtRAAKeA"
      },
      "outputs": [],
      "source": [
        "# Set the desired size of the image\n",
        "img_size = 100\n",
        "\n",
        "# The following line creates a transform which converts the np.array to a PIL Image.\n",
        "# It then resizes the image to img_size x img_size and converts the image to a tensor\n",
        "\n",
        "transform = transforms.Compose([transforms.ToPILImage(),transforms.Resize(img_size),transforms.ToTensor()])\n",
        "\n",
        "# Generate the dataset containing all the samples\n",
        "ghi_dataset = GHIDataset(path,'labels.npy','X.npy','meteo.xlsx','ground_truth.npy','time.npy',transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp4jRpCWtoLW"
      },
      "source": [
        "## Data management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ2ESNdQjdgz"
      },
      "source": [
        "The data need to be splitted between train and test set.\n",
        "\n",
        "Here we define a function to split the dataset into a test set, a validation set and a train set.\n",
        "\n",
        "We also define a function to split the dataset in a given site to choose the test set we want.\n",
        "\n",
        "Note that we do not shuffle the data as it is time dependent. What is significant here is that we test for the last values of the set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "k1Xp7M2qMhGV"
      },
      "outputs": [],
      "source": [
        "def split_at_location(dataset, location = 0, length = 100):\n",
        "    \"\"\"\n",
        "      This function allows to extract the test or validation set at a given location in the dataset\n",
        "        Arguments:\n",
        "            location  (int) : position in the dataset where the test/validation set will start\n",
        "            length    (int) : length of the test/validation set\n",
        "        \"\"\"\n",
        "    # Initialise the indices of the dataset\n",
        "    dataset_idx = np.arange(len(dataset))\n",
        "    # Compute start and stop indices of the test/validation set while preventing out-of-range targets\n",
        "    start_idx = max(0,location)\n",
        "    end_idx = min(len(dataset),location+length)\n",
        "    validation_idx = dataset_idx[start_idx:end_idx]\n",
        "\n",
        "    # Compute the indices of the training set by removing the ones of the test/validation set.\n",
        "    train_idx = np.concatenate([dataset_idx[:start_idx], dataset_idx[end_idx:]])\n",
        "\n",
        "    # Return the two sets\n",
        "    return Subset(dataset, train_idx), Subset(dataset, validation_idx)\n",
        "\n",
        "def train_val_dataset(dataset,test_split=0.8, val_split=0.2):\n",
        "    \"\"\"\n",
        "      split dataset in train set, validation set, test set\n",
        "    \"\"\"\n",
        "\n",
        "    test_idx, train_idx = train_test_split(list(range(len(dataset))), test_size=test_split,shuffle=False)\n",
        "    train_idx, val_idx = train_test_split(train_idx,test_size=val_split,shuffle=False)\n",
        "\n",
        "    return Subset(dataset, train_idx), Subset(dataset, val_idx), Subset(dataset, test_idx)\n",
        "\n",
        "def shuffle(dataset) :\n",
        "  \"\"\"\n",
        "      This function allows to shuffle the data in the given set\n",
        "  \"\"\"\n",
        "\n",
        "  data_idx = np.arange(len(dataset))\n",
        "  random.shuffle(data_idx)\n",
        "  #print(data_idx)\n",
        "  return Subset(dataset, data_idx)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PXyi0Y6W3rp"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VRaudRjLFfX",
        "outputId": "2c19e7c8-92e3-40d7-d3a3-0428c4947327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10293\n",
            "400\n"
          ]
        }
      ],
      "source": [
        "location = 1270\n",
        "\n",
        "ghi_train, ghi_test = split_at_location(ghi_dataset, location, 400)\n",
        "\n",
        "print(len(ghi_train))\n",
        "print(len(ghi_test))\n",
        "\n",
        "# below : in case of only one validation set, no cross validation\n",
        "\n",
        "#ghi_train ,ghi_val= split_at_location(ghi_train, 0, round(len(ghi_train)*0.10))\n",
        "\n",
        "#define the loader !\n",
        "#train_loader = DataLoader(ghi_train, batch_sampler=SequentialBatchSampler(np.arange(len(ghi_train)), batch_size=32, dec = 32))\n",
        "#test_loader = DataLoader(ghi_test, batch_sampler=SequentialBatchSampler(np.arange(len(ghi_test)), batch_size=32, dec = 32))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLXBt6j0kEGp"
      },
      "source": [
        "Finally we create the dataloader, to iterate on it as we compute each epoch.\n",
        "\n",
        "We define a custom batch sampler because we need to conserve the order of the samples in each batch. Moreover, we want the stride between each batch to be one and not the batch size. Such that for a dataset = [1,2,3,4,5,6] and a batch size of 3 we get [1,2,3], [2,3,4], [3,4,5], [4,5,6] as batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zNkGWmZJnUfY"
      },
      "outputs": [],
      "source": [
        "class SequentialBatchSampler:\n",
        "    def __init__(self, data_source, batch_size, dec):\n",
        "        self.data_source = data_source\n",
        "        self.batch_size = batch_size\n",
        "        self.dec = dec\n",
        "\n",
        "    def __iter__(self):\n",
        "      i = 0\n",
        "      while i <= len(self.data_source)-self.batch_size-1:\n",
        "        yield self.data_source[i:i+self.batch_size]\n",
        "        i += self.dec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie1V2awfrctB"
      },
      "source": [
        "## Models\n",
        "\n",
        "we defined and tested several models for our purpose.\n",
        "\n",
        "- Only taking in account the images, convolutionnal layer + LSTM\n",
        "- Taking in account the images and meteo data (not implemented yet)\n",
        "- Transformer (not implemented yet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7_3bRAPx9oN"
      },
      "source": [
        "This neural network will take in account meteo data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "EtbOaqwVY9zH"
      },
      "outputs": [],
      "source": [
        "class Net2(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout1 = 0.3, dropout2 = 0.1, out_channels=16, kernel_size1=3, kernel_size2=2, kernel_Size3 = 3):\n",
        "        super(Net2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(6, out_channels, kernel_size1) # input channels to 6 because 2 images ! (RGBx2)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size2)\n",
        "        self.drop1 = nn.Dropout2d(p=dropout1)\n",
        "        self.conv3 = nn.Conv2d(out_channels, 2*out_channels, kernel_size = kernel_size3)\n",
        "        self.bn3 = nn.BatchNorm2d(2*out_channels)\n",
        "        self.conv4 = nn.Conv2d(2*out_channels, 2*out_channels, kernel_size3)\n",
        "        self.bn4 = nn.BatchNorm2d(2*out_channels)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size2)\n",
        "        self.drop2 = nn.Dropout2d(p=dropout2)\n",
        "        #self.linear_layer = nn.Linear(5, 32*22*22)  # 5 is the number of additional features\n",
        "        self.lstm1 = nn.LSTM(2*out_channels* 22* 22, 8*out_channels, batch_first=True)\n",
        "        self.lstm2 = nn.LSTM(8*out_channels, 4*out_channels, batch_first=True)\n",
        "        self.fc1 = nn.Linear(4*out_channels, 4*out_channels)\n",
        "        self.fc2 = nn.Linear(4*out_channels*2, 1)\n",
        "\n",
        "        # Skip connections\n",
        "        self.skip_conv1 = nn.Conv2d(6, 32, kernel_size=1)  # Adjust channels as needed\n",
        "        self.skip_conv2 = nn.Conv2d(32, 32, kernel_size=1)  # Adjust channels as needed\n",
        "\n",
        "        # Additional features processing\n",
        "        self.additional_fc1 = nn.Linear(9, 4*out_channels)  # Adjust input size and output size\n",
        "        self.additional_fc2 = nn.Linear(4*out_channels, 4*out_channels)  # Adjust output size\n",
        "\n",
        "\n",
        "    def forward(self, x1,x2, day, month, year, hour, minute, GHI, air_temp, wind_speed, wind_dir): #x1 and x2 correspond to the 2 images\n",
        "\n",
        "        x = torch.cat((x1, x2), dim=1)  # Concatenate along the channel dimension\n",
        "\n",
        "        #x_skip1 = F.relu(self.skip_conv1(x))  # Skip connection 1\n",
        "\n",
        "        x = F.relu(self.conv1(x)) # add relu activation function\n",
        "        x = self.bn1(x)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.bn2(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.drop1(x)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.bn4(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.drop2(x)\n",
        "\n",
        "        #x_skip2 = F.relu(self.skip_conv2(x))  # Skip connection 2\n",
        "\n",
        "        x = x.view(-1, 32* 22* 22)\n",
        "        x = x.unsqueeze(1)\n",
        "\n",
        "        x, _ = self.lstm1(x)\n",
        "        x, _ = self.lstm2(x)\n",
        "\n",
        "        x = F.relu(self.fc1(x[:, -1, :]))\n",
        "\n",
        "        # Combine image features with skip connections\n",
        "        #x_skip1 = x_skip1.view(x_skip1.size(0), -1).unsqueeze(2).unsqueeze(3)\n",
        "        #x_skip2 = x_skip2.view(x_skip2.size(0), -1).unsqueeze(2).unsqueeze(3)\n",
        "        #x = x + x_skip1 + x_skip2\n",
        "\n",
        "        # Concatenate the additional features into a single tensor\n",
        "        additional_features = torch.stack((day, month, year, hour, minute, GHI, air_temp, wind_speed, wind_dir), dim=1)\n",
        "\n",
        "        additional_features = additional_features.to(torch.float32)  # Convert to torch.FloatTensor\n",
        "\n",
        "        # Apply the linear layer to the concatenated additional features\n",
        "        additional_features = F.relu(self.additional_fc1(additional_features))\n",
        "        additional_features = F.relu(self.additional_fc2(additional_features))\n",
        "\n",
        "        # Combine with additional features\n",
        "\n",
        "        x_combined = torch.cat((x, additional_features*10), dim=1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x_combined = self.fc2(x_combined)\n",
        "        x_combined = x_combined.squeeze()\n",
        "\n",
        "        return x_combined"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmzP9S3ryFAt"
      },
      "source": [
        "## Cross-validation and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vTz9bUS9mxQm"
      },
      "outputs": [],
      "source": [
        "def RMSELoss(yhat,y): #defining RMSE\n",
        "    return torch.sqrt(torch.mean((yhat-y)**2))\n",
        "\n",
        "def reset_weights(m):\n",
        "  '''\n",
        "    Method to reset the model weights between each fold or utilization\n",
        "    Avoid weight leakage.\n",
        "  '''\n",
        "  for layer in m.children():\n",
        "   if hasattr(layer, 'reset_parameters'):\n",
        "    print(f'Reset trainable parameters of layer = {layer}')\n",
        "    layer.reset_parameters()\n",
        "\n",
        "def train_epoch(model, optimizer, criterion, train_loader, epoch, device):\n",
        "  \"\"\"\n",
        "    method to train the model on a given training set\n",
        "    return the loss at each step\n",
        "  \"\"\"\n",
        "  # Set model to training mode (affects dropout, batch norm e.g.)\n",
        "  model.train()\n",
        "  loss_history = []\n",
        "  lr_history = []\n",
        "  # loop to get batch_idx, data and target from train_loader\n",
        "  for batch_idx, (image0, image1, day, month, year, hour, minute, GHI, air_temp, wind_speed, wind_dir, target) in enumerate(train_loader):\n",
        "\n",
        "      # Move the data to the device\n",
        "      image0,image1,day, month, year, hour, minute, GHI, air_temp, wind_speed, wind_dir, target = image0.to(device),image1.to(device), day.to(device), month.to(device), year.to(device), hour.to(device), minute.to(device), GHI.to(device), air_temp.to(device), wind_speed.to(device), wind_dir.to(device), target.to(device)\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "      # Compute model output\n",
        "      output = model(image0,image1, day, month, year, hour, minute, GHI, air_temp, wind_speed, wind_dir)\n",
        "      output = output.to(torch.float64)\n",
        "      # Compute loss\n",
        "      loss = criterion(output, target)\n",
        "      # Backpropagate loss\n",
        "      loss.backward()\n",
        "      # Perform an optimizer step\n",
        "      optimizer.step()\n",
        "      # Compute loss (float value, not a tensor)\n",
        "      loss_float = loss.item()\n",
        "\n",
        "      loss_history.append(loss_float)\n",
        "  print(\n",
        "    f\"Train Epoch : {epoch}\"\n",
        "    f\"train_loss = {np.mean(loss_history)} \"\n",
        "  )\n",
        "\n",
        "  return loss_history\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(model, device, val_loader, criterion):\n",
        "  \"\"\"\n",
        "    method to validate the model on a given validation set\n",
        "    return the loss at each step\n",
        "  \"\"\"\n",
        "  model.eval()  # Important: eval mode (affects dropout, batch norm etc)\n",
        "  test_loss = 0\n",
        "  history = []\n",
        "\n",
        "  for image0, image1, target in val_loader:\n",
        "    image0,image1, target = image0.to(device),image1.to(device), target.to(device)\n",
        "    output = model(image0,image1)\n",
        "    test_loss = criterion(output, target).item()\n",
        "    history.append(test_loss)\n",
        "\n",
        "  print(\n",
        "    \"Test set: Average loss: {:.4f}\".format(\n",
        "       np.mean(history),\n",
        "       len(val_loader.dataset)\n",
        "      )\n",
        "  )\n",
        "  return history"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross-validation\n",
        "Hyper-paremeters to tune:\n",
        "- Kernel sizes : size of the different filters\n",
        "- Dropout rates: there are two dropout rates to hyperparameter\n",
        "- Batch-size\n",
        "- Activation function maybe (Softmax, ReLu, Softplus, Leaky ReLu, PReLu)\n",
        "- number of epoch"
      ],
      "metadata": {
        "id": "yj_iudOZ7iKr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sCGcdD4ooB5O",
        "outputId": "5bfcc297-7a97-4a64-fbfa-02b175e16e69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold  1\n",
            "Reset trainable parameters of layer = Conv2d(6, 8, kernel_size=(2, 2), stride=(1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv2d(8, 8, kernel_size=(2, 2), stride=(1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv2d(8, 16, kernel_size=(2, 3, 4), stride=(1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv2d(16, 16, kernel_size=(2, 3, 4), stride=(1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = LSTM(7744, 64, batch_first=True)\n",
            "Reset trainable parameters of layer = LSTM(64, 32, batch_first=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=1, bias=True)\n",
            "Reset trainable parameters of layer = Conv2d(6, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Linear(in_features=9, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=32, bias=True)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-6fc0d2c969f6>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m       \u001b[0mval_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m       \u001b[0;31m#train_loss_history.extend(train_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mtrain_loss_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-7517d1a9f8d8>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, criterion, train_loader, epoch, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0;31m# Compute model output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhour\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGHI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mair_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwind_speed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwind_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-91595c22adb7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, day, month, year, hour, minute, GHI, air_temp, wind_speed, wind_dir)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: expected stride to be a single integer value or a list of 3 values to match the convolution dimensions, but got stride=[1, 1]"
          ]
        }
      ],
      "source": [
        "# parameter for the training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Constant\n",
        "\n",
        "optimizer_kwargs = dict(\n",
        "    lr=5e-4,\n",
        "    weight_decay=1e-3,\n",
        ") # constant\n",
        "\n",
        "# Variables\n",
        "kernel_size1 = [2, 3, 4] #For first conv2d\n",
        "kernel_size2 = [2, 3] #For MaxPool2d\n",
        "kernel_size3 = [2, 3, 4] #For second conv2d\n",
        "dropout1 = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6] # Dropout rates for the first layer\n",
        "dropout2 = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6] # Dropout rates for the second layer\n",
        "batch_size = [8, 16, 32]\n",
        "out_channels = [8, 16, 32] #number of channels coming out of the first convolution\n",
        "num_epochs = 30\n",
        "\n",
        "# Combine hyperparameters\n",
        "hyperparameter_combinations = list(itertools.product(kernel_size1, kernel_size2, kernel_size3, dropout1, dropout2, batch_size, out_channels))\n",
        "\n",
        "# Define the K-fold Cross Validation\n",
        "folds = 5\n",
        "kfold = KFold(n_splits=folds, shuffle=True)\n",
        "criterion = RMSELoss #criterion for the training\n",
        "\n",
        "\n",
        "# initialize each variables\n",
        "result_model = []\n",
        "result_best_val_loss = []  # Initialize with positive infinity\n",
        "result_best_epoch = []\n",
        "\n",
        "\n",
        "\n",
        "#iterate on each fold\n",
        "for kernel1, kernel2, kernel3, dpt1, dpt2, batch_size_, out in hyperparameter_combinations :\n",
        "\n",
        "  model = Net2(dropout1 = dpt1, dropout2 = dpt2, out_channels=out, kernel_size1=kernel1, kernel_size2=kernel2, kernel_Size3 = kernel3)\n",
        "  model = model.to(device=device)\n",
        "\n",
        "  for fold, (train_ids, test_ids) in enumerate(kfold.split(ghi_train)):\n",
        "\n",
        "\n",
        "      print(\"fold \", fold+1) # just by convenience, first fold, second fold....\n",
        "\n",
        "      # prepare the train and validation set and corresponding loaders\n",
        "      train = Subset(ghi_train, train_ids)\n",
        "      test = Subset(ghi_train, test_ids)\n",
        "      #define the loader\n",
        "      train_loader = DataLoader(train, batch_sampler=SequentialBatchSampler(np.arange(len(train)), batch_size=batch_size_, dec = batch_size_))\n",
        "      val_loader = DataLoader(test, batch_sampler=SequentialBatchSampler(np.arange(len(test)), batch_size=batch_size_, dec = batch_size_))\n",
        "\n",
        "      #prepare the model\n",
        "      model.apply(reset_weights)\n",
        "      optimizer = torch.optim.AdamW(model.parameters(), **optimizer_kwargs)\n",
        "\n",
        "      # ===== Train Model =====\n",
        "      best_val_loss = float('inf')  # Initialize with positive infinity\n",
        "      best_epoch = 0\n",
        "      #train_loss_history = []\n",
        "      train_loss_step = []\n",
        "      #val_loss_history = []\n",
        "      val_loss_step = []\n",
        "      for epoch in range(1, num_epochs + 1):\n",
        "        train_loss = train_epoch(model, optimizer, criterion, train_loader, epoch, device)\n",
        "      #train_loss_history.extend(train_loss)\n",
        "        train_loss_step.append(np.mean(train_loss))\n",
        "\n",
        "        val_loss = validate(model, device, val_loader, criterion)\n",
        "      #val_loss_history.extend(val_loss)\n",
        "        loss = np.mean(val_loss)\n",
        "        val_loss_step.append(loss)\n",
        "\n",
        "      # Save the model with the lowest validation loss\n",
        "        if loss < best_val_loss:\n",
        "          best_val_loss = loss\n",
        "          best_epoch = epoch\n",
        "          best_model_state = model.state_dict()\n",
        "\n",
        "      print(\"best loss\",best_val_loss, \"epoch\", best_epoch)\n",
        "      result_model.append(best_model_state)\n",
        "      result_best_val_loss.append(best_val_loss)\n",
        "      result_best_epoch.append(best_epoch)\n",
        "\n",
        "      # ===== Plot training curves =====\n",
        "      t_val = np.arange(1, num_epochs + 1)\n",
        "\n",
        "    # Increase the size of the plot\n",
        "      plt.figure(figsize=(20, 16))\n",
        "\n",
        "      plt.subplot(2, 3, 2)\n",
        "      plt.plot(t_val, train_loss_step, label=\"Train\")\n",
        "      plt.plot(t_val, val_loss_step, label=\"Val\")\n",
        "      plt.legend()\n",
        "      plt.xlabel(\"Epoch\")\n",
        "      plt.ylabel(\"Loss\")\n",
        "      plt.show()\n",
        "\n",
        "  # define best parameters\n",
        "  mean_loss = np.mean(result_best_val_loss)\n",
        "  mean_epoch = math.ceil(np.mean(result_best_epoch))\n",
        "  print(\"best loss\",np.mean(result_best_val_loss), \"epoch\", mean_epoch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Net2 (with other parameters)\n"
      ],
      "metadata": {
        "id": "k7ApVkEVXsY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parameter for the training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "optimizer_kwargs = dict( # how did you decice that ?\n",
        "    lr=5e-4,\n",
        "    weight_decay=1e-3,\n",
        ")\n",
        "\n",
        "model = Net2()\n",
        "model = model.to(device=device)\n",
        "model.apply(reset_weights)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), **optimizer_kwargs)\n",
        "\n",
        "\n",
        "criterion = RMSELoss #criterion for the training\n",
        "\n",
        "#parameter\n",
        "#num_epochs = mean_epoch\n",
        "num_epochs = 25\n",
        "\n",
        "#define the loader\n",
        "ghi_train_shuffle = shuffle(ghi_train)\n",
        "train_loader = DataLoader(ghi_train_shuffle, batch_sampler=SequentialBatchSampler(np.arange(len(ghi_train_shuffle)), batch_size=8, dec = 8))\n",
        "\n",
        "# ===== Train Model =====\n",
        "train_loss_history = []\n",
        "train_loss_step = []\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "  train_loss = train_epoch(model, optimizer, criterion, train_loader, epoch, device)\n",
        "  train_loss_history.extend(train_loss)\n",
        "  train_loss_step.append(np.mean(train_loss))\n",
        "\n",
        "# ===== Plot training curves =====\n",
        "t_val = np.arange(1, num_epochs + 1)\n",
        "\n",
        "# Increase the size of the plot\n",
        "plt.figure(figsize=(20, 16))\n",
        "\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.plot(t_val, train_loss_step, label=\"Train\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "# Increase the size of the plot\n",
        "plt.figure(figsize=(40, 16))\n",
        "\n",
        "t_train = np.arange(1, len(train_loss_history) + 1)/len(train_loss_history)*num_epochs\n",
        "\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.plot(t_train, train_loss_history, label=\"Train\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Increase the size of the plot\n",
        "plt.figure(figsize=(40, 16))\n",
        "\n",
        "\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.plot(t_train[0:360], train_loss_history[0:360], label=\"Train\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Increase the size of the plot\n",
        "plt.figure(figsize=(40, 16))\n",
        "\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.plot(t_train[-361:-1], train_loss_history[-361:-1], label=\"Train\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "f4qOzVC4XvXG",
        "outputId": "ee606a70-97f9-4d3f-9376-ec0f72e4249c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reset trainable parameters of layer = Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = LSTM(15488, 128, batch_first=True)\n",
            "Reset trainable parameters of layer = LSTM(128, 64, batch_first=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=1, bias=True)\n",
            "Reset trainable parameters of layer = Conv2d(6, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Linear(in_features=9, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=64, bias=True)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-59b3bdca44db>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mtrain_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m   \u001b[0mtrain_loss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0mtrain_loss_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-7517d1a9f8d8>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, criterion, train_loader, epoch, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0;31m# Compute model output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhour\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGHI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mair_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwind_speed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwind_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-934d35d2e1b3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, day, month, year, hour, minute, GHI, air_temp, wind_speed, wind_dir)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Concatenate along the channel dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-3, 2], but got 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Net2"
      ],
      "metadata": {
        "id": "LL24YlGtYHrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(ghi_test, batch_sampler=SequentialBatchSampler(np.arange(len(ghi_test)), batch_size=8, dec = 8))\n",
        "\n",
        "pred = []\n",
        "truth = []\n",
        "test_loss = []\n",
        "model.eval()\n",
        "for image0,image1,day, month, year, hour, minute, GHI, air_temp, wind_speed, wind_dir, target in test_loader:\n",
        "  image0,image1,day, month, year, hour, minute, GHI, air_temp, wind_speed, wind_dir, target = image0.to(device),image1.to(device), day.to(device), month.to(device), year.to(device), hour.to(device), minute.to(device), GHI.to(device), air_temp.to(device), wind_speed.to(device), wind_dir.to(device), target.to(device)\n",
        "  output = model(image0,image1,day, month, year, hour, minute, GHI, air_temp, wind_speed, wind_dir)\n",
        "\n",
        "  pred.extend(output.tolist())\n",
        "  truth.extend(target.tolist())\n",
        "  test_loss.append(criterion(output, target).item())\n",
        "\n",
        "Loss = np.mean(test_loss)\n",
        "\n",
        "print(\"the test loss is \",Loss)\n",
        "#### a plot to visualize our predictions vs the true vlaues\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.plot(pred, 'g', label = \"Predictions\")\n",
        "plt.plot(truth, '--k',label = 'Truth')\n",
        "plt.legend(loc = 'best')"
      ],
      "metadata": {
        "id": "nTpF_x9cX9i_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YuL3ZnRZ782E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}